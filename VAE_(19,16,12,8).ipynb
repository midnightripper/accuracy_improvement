{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPBz1Q8++GYfnKCFr+xEfjd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/midnightripper/accuracy_improvement/blob/main/VAE_(19%2C16%2C12%2C8).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n4W5sADBnfx",
        "outputId": "7d4b1414-bd67-4c59-b2f9-dbb20d6e03ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTuKWTvUCDYg"
      },
      "source": [
        "###Prerequisite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd7zXfrBBvqM",
        "outputId": "fbc40820-685e-4805-e0ef-d738edfb8fdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.9/dist-packages (0.20.0)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.9/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow-addons) (23.1)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O7F71cx6BwQW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b50313-3138-47d6-906d-7eb290363d02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Input\n",
        "from keras.layers import Reshape\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzQisdLRCdAm"
      },
      "source": [
        "Load the train and test data splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c4yofhKpCPsk"
      },
      "outputs": [],
      "source": [
        "GER_test = (np.array(sio.loadmat('/content/drive/MyDrive/training data/GER_test.mat')['GER_test'])).transpose()\n",
        "GER_train = (np.array(sio.loadmat('/content/drive/MyDrive/training data/GER_train.mat')['GER_train'])).transpose()\n",
        "test_frame = pd.DataFrame(GER_test).sort_values(1)\n",
        "train_frame = pd.DataFrame(GER_train).sort_values(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HDdLVz2ChJF",
        "outputId": "8eec03ec-2619-4ecd-8dfb-c0c0e8397ed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (6981, 21) - y_train shape: (6981, 21)\n",
            "x_test shape: (6248, 21) - y_test shape: (6248, 21)\n"
          ]
        }
      ],
      "source": [
        "print(f\"x_train shape: {GER_train.shape} - y_train shape: {GER_train.shape}\")\n",
        "print(f\"x_test shape: {GER_test.shape} - y_test shape: {GER_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QKt4urE1O7ke"
      },
      "outputs": [],
      "source": [
        "def get_data_labels(split):\n",
        "    x = pd.DataFrame(split)\n",
        "    labels = x[0].values.astype(np.uint8)\n",
        "    del x[0],x[1]\n",
        "    data = x.values \n",
        "    return data, labels\n",
        "    \n",
        "x_train, y_train = get_data_labels(train_frame.values.tolist())\n",
        "x_test, y_test = get_data_labels(test_frame.values.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(x_train)\n",
        "scaler = StandardScaler()\n",
        "x_train = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)"
      ],
      "metadata": {
        "id": "LiyxoXMIajC_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame(x_test)\n",
        "scaler = StandardScaler()\n",
        "x_test = pd.DataFrame(scaler.fit_transform(df2), columns=df.columns)"
      ],
      "metadata": {
        "id": "4PVlJpiAb1Xq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKBwpU_zGRYP",
        "outputId": "c5798298-49c3-4d97-e4b0-aa4200ee0b5d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     5.699813e-17\n",
            "1    -1.628518e-17\n",
            "2     1.791370e-16\n",
            "3     8.142590e-18\n",
            "4    -4.071295e-18\n",
            "5    -4.274860e-16\n",
            "6    -8.676947e-17\n",
            "7     8.549719e-17\n",
            "8     7.302885e-17\n",
            "9    -4.885554e-17\n",
            "10    9.771108e-17\n",
            "11    3.257036e-17\n",
            "12    1.302814e-16\n",
            "13    8.386867e-16\n",
            "14    1.526736e-18\n",
            "15    2.157786e-16\n",
            "16    2.015291e-16\n",
            "17    9.440315e-17\n",
            "18    8.193481e-17\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWxgdQ8JGc5S",
        "outputId": "0a37592d-f8e1-4459-df73-17e041ab93f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     1.000072\n",
            "1     1.000072\n",
            "2     1.000072\n",
            "3     1.000072\n",
            "4     1.000072\n",
            "5     1.000072\n",
            "6     1.000072\n",
            "7     1.000072\n",
            "8     1.000072\n",
            "9     1.000072\n",
            "10    1.000072\n",
            "11    1.000072\n",
            "12    1.000072\n",
            "13    1.000072\n",
            "14    1.000072\n",
            "15    1.000072\n",
            "16    1.000072\n",
            "17    1.000072\n",
            "18    1.000072\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Size of the training set: {len(x_train)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNcb5GGX3-RC",
        "outputId": "b8ea7e36-9d3d-4270-b439-a7a12309fee6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the training set: 6981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Size of the x training set: {len(x_train)}\")\n",
        "print(f\"Size of the x validation set: {len(x_val)}\")\n",
        "print(f\"Size of the y training set: {len(y_train)}\")\n",
        "print(f\"Size of the y validation set: {len(y_val)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8QrrTLl3Vck",
        "outputId": "d2cd4e87-ae88-4bcc-fcd5-c749687e7573"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the x training set: 5584\n",
            "Size of the x validation set: 1397\n",
            "Size of the y training set: 5584\n",
            "Size of the y validation set: 1397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[:5])\n",
        "print(y_train[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIJuIEhcCR9z",
        "outputId": "a0b1964f-891d-41a7-cb41-4465e98d6ab8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            0         1         2         3         4         5         6   \\\n",
            "6565 -1.076680 -1.065748 -1.012843 -0.799906 -0.713923 -0.710367 -1.932554   \n",
            "4003  0.582947  1.135969  1.297658  1.015694  0.868769 -0.130759 -1.806106   \n",
            "1010 -0.545586 -0.653364 -0.430347 -0.782925 -0.775639 -0.323475 -0.652264   \n",
            "4617 -0.566326 -0.578170 -0.686170 -0.379677 -0.210357 -1.287966  0.392749   \n",
            "931   0.245015  0.061639  0.443537 -0.616326 -0.935091  0.915754  0.721268   \n",
            "\n",
            "            7         8         9         10        11        12        13  \\\n",
            "6565  2.396384 -0.985383 -0.853229 -0.838086 -0.790418 -0.770441  1.082992   \n",
            "4003  1.601756 -0.026166  1.974222  2.026149  2.399590  2.084844 -0.682288   \n",
            "1010  0.034567 -1.103360  0.015721  0.285905  0.997402  0.964844 -2.012156   \n",
            "4617 -0.268374 -0.030353 -0.463698 -0.261271  1.170901  1.321986 -2.641625   \n",
            "931  -0.828500 -0.803408 -0.062883 -0.065124 -0.179201 -0.313890  0.995570   \n",
            "\n",
            "            14        15        16        17        18  \n",
            "6565 -0.216355 -0.721598 -0.594885 -0.737281 -0.471763  \n",
            "4003 -1.046685  0.347734  0.734827  0.719801  0.505871  \n",
            "1010 -1.826764  1.715625  0.002333 -0.291287 -0.845277  \n",
            "4617 -1.741099  1.721965  0.407782  0.506096 -1.018501  \n",
            "931   0.347777 -0.748741 -0.701084 -0.737281 -1.479453  \n",
            "[0 1 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early stopping to prevent over-fitting"
      ],
      "metadata": {
        "id": "NDyM8dez-mGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
      ],
      "metadata": {
        "id": "g8hamCaPnco_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Function Calls"
      ],
      "metadata": {
        "id": "9yq9R7CC9ZZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (19,)"
      ],
      "metadata": {
        "id": "t-_jwVqoJgTE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sampling layer\n",
        "# def sampling(args):\n",
        "#     z_mean, z_log_var = args\n",
        "#     epsilon = tf.keras.backend.random_normal(shape=(tf.keras.backend.shape(z_mean)[0], 19), mean=0., stddev=0.00001)\n",
        "#     return z_mean + tf.keras.backend.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "def sampling(args):\n",
        "    \"\"\"Reparameterization trick. Instead of sampling from Q(z|X), \n",
        "    sample eps = N(0,I) z = z_mean + sqrt(var)*eps.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    args: list of Tensors\n",
        "        Mean and log of variance of Q(z|X)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    z: Tensor\n",
        "        Sampled latent vector\n",
        "    \"\"\"\n",
        "\n",
        "    z_mean, z_log_var = args\n",
        "    eps = tf.random.normal(tf.shape(z_log_var), dtype=tf.float32, mean=0., stddev=1 , name='epsilon')\n",
        "    z = z_mean + tf.exp(z_log_var / 2) * eps\n",
        "    return z"
      ],
      "metadata": {
        "id": "jakg8MGkJmpg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "Vm4A3lZA9mFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.layers.Input(shape=input_shape, name='input')\n",
        "x = keras.layers.Dense(36, activation='relu')(inputs)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "x = keras.layers.Dense(72, activation='relu')(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "z_mean = keras.layers.Dense(36, name='z_mean')(x)\n",
        "z_log_var = keras.layers.Dense(36, name='z_log_var')(x)"
      ],
      "metadata": {
        "id": "05L3ufM33CIC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = keras.layers.Lambda(sampling, name='z')([z_mean, z_log_var])\n",
        "encoder = keras.Model(inputs, z , name='encoder')\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "Wbei5NfYOybb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4039530d-584e-4263-f9de-0358c70ebdb4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 19)]         0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 36)           720         ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 72)           2664        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 36)           2628        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 36)           2628        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " z (Lambda)                     (None, 36)           0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,640\n",
            "Trainable params: 8,640\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder"
      ],
      "metadata": {
        "id": "f8zXzzoi9yVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Giving input to decoder and initialising shape\n",
        "# latent_inputs = keras.layers.Input(shape=(8), name='z_sampling')\n",
        "\n",
        "latent_inputs = keras.layers.Dense(72, activation='relu')(z)\n",
        "# x = layers.Dropout(0.5)(latent_inputs)\n",
        "x = keras.layers.Dense(36, activation='relu')(latent_inputs)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "# middle=keras.layers.Dense(16, activation='relu')(x)\n",
        "outputs = keras.layers.Dense(19, activation='relu')(x)\n",
        "\n",
        "\n",
        "# instantiate decoder model\n",
        "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "yuxKxPh74BnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d198b09c-b167-4013-8dcc-8bd2c8a4ea4e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 72)]              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 36)                2628      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 19)                703       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,331\n",
            "Trainable params: 3,331\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UKVtGc6100x",
        "outputId": "a1a7e52c-cd6b-4a6c-8a7c-718869784b5d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 19), dtype=tf.float32, name=None), name='dense_4/Relu:0', description=\"created by layer 'dense_4'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing VAE without Loss"
      ],
      "metadata": {
        "id": "2Yc5C5Ps9_1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialising Loss "
      ],
      "metadata": {
        "id": "p00pZecn-H63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "bY7oxb8C98Zu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnQK_HBs-iTq",
        "outputId": "914879e9-8844-48c2-882d-52b61d43b6eb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 19)]         0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 36)           720         ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 72)           2664        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 36)           2628        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 36)           2628        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " z (Lambda)                     (None, 36)           0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 72)           2664        ['z[0][0]']                      \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 36)           2628        ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 19)           703         ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,635\n",
            "Trainable params: 14,635\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruction_loss = K.mean(K.square(outputs - inputs), axis=-1)\n",
        "kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)"
      ],
      "metadata": {
        "id": "rFGVeXkk-r-K"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training VAE"
      ],
      "metadata": {
        "id": "HEPth6TP-X_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.add_loss(vae_loss)\n",
        "autoencoder.summary()\n",
        "autoencoder.compile(optimizer='adam')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR8Q2yDgmhUz",
        "outputId": "d28c82fb-649a-4f04-ef0f-fcb2af928534"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 19)]         0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 36)           720         ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 72)           2664        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 36)           2628        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 36)           2628        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " z (Lambda)                     (None, 36)           0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 72)           2664        ['z[0][0]']                      \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 36)           2628        ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 19)           703         ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 36)          0           ['z_log_var[0][0]']              \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.square_1 (TFOpLambda)  (None, 36)           0           ['z_mean[0][0]']                 \n",
            "                                                                                                  \n",
            " tf.math.subtract_1 (TFOpLambda  (None, 36)          0           ['tf.__operators__.add[0][0]',   \n",
            " )                                                                'tf.math.square_1[0][0]']       \n",
            "                                                                                                  \n",
            " tf.math.exp (TFOpLambda)       (None, 36)           0           ['z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            " tf.math.subtract (TFOpLambda)  (None, 19)           0           ['dense_4[0][0]',                \n",
            "                                                                  'input[0][0]']                  \n",
            "                                                                                                  \n",
            " tf.math.subtract_2 (TFOpLambda  (None, 36)          0           ['tf.math.subtract_1[0][0]',     \n",
            " )                                                                'tf.math.exp[0][0]']            \n",
            "                                                                                                  \n",
            " tf.math.square (TFOpLambda)    (None, 19)           0           ['tf.math.subtract[0][0]']       \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum (TFOpLambda  (None,)             0           ['tf.math.subtract_2[0][0]']     \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean (TFOpLambd  (None,)             0           ['tf.math.square[0][0]']         \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  (None,)              0           ['tf.math.reduce_sum[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None,)             0           ['tf.math.reduce_mean[0][0]',    \n",
            " mbda)                                                            'tf.math.multiply[0][0]']       \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_1 (TFOpLam  ()                  0           ['tf.__operators__.add_1[0][0]'] \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " add_loss (AddLoss)             ()                   0           ['tf.math.reduce_mean_1[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,635\n",
            "Trainable params: 14,635\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(x_train, x_train,\n",
        "                epochs=200,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_val,x_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lbw85BPmRkp-",
        "outputId": "6c21a0cf-8a9a-4bc9-b2e9-4440c32b5e41"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "44/44 [==============================] - 3s 14ms/step - loss: 1.9324 - val_loss: 1.2764\n",
            "Epoch 2/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1.1479 - val_loss: 1.1271\n",
            "Epoch 3/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 1.0629 - val_loss: 1.0764\n",
            "Epoch 4/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 1.0274 - val_loss: 1.0520\n",
            "Epoch 5/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 1.0104 - val_loss: 1.0413\n",
            "Epoch 6/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1.0020 - val_loss: 1.0361\n",
            "Epoch 7/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 1.0003 - val_loss: 1.0328\n",
            "Epoch 8/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9967 - val_loss: 1.0313\n",
            "Epoch 9/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9962 - val_loss: 1.0302\n",
            "Epoch 10/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9970 - val_loss: 1.0298\n",
            "Epoch 11/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9937 - val_loss: 1.0295\n",
            "Epoch 12/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9936 - val_loss: 1.0292\n",
            "Epoch 13/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9950 - val_loss: 1.0290\n",
            "Epoch 14/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9947 - val_loss: 1.0289\n",
            "Epoch 15/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9942 - val_loss: 1.0287\n",
            "Epoch 16/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9932 - val_loss: 1.0286\n",
            "Epoch 17/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9929 - val_loss: 1.0285\n",
            "Epoch 18/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9937 - val_loss: 1.0285\n",
            "Epoch 19/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9930 - val_loss: 1.0284\n",
            "Epoch 20/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9924 - val_loss: 1.0285\n",
            "Epoch 21/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9924 - val_loss: 1.0284\n",
            "Epoch 22/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9931 - val_loss: 1.0284\n",
            "Epoch 23/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9927 - val_loss: 1.0284\n",
            "Epoch 24/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9933 - val_loss: 1.0284\n",
            "Epoch 25/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.9929 - val_loss: 1.0283\n",
            "Epoch 26/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9921 - val_loss: 1.0283\n",
            "Epoch 27/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9922 - val_loss: 1.0283\n",
            "Epoch 28/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9963 - val_loss: 1.0283\n",
            "Epoch 29/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9930 - val_loss: 1.0283\n",
            "Epoch 30/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9936 - val_loss: 1.0283\n",
            "Epoch 31/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9919 - val_loss: 1.0283\n",
            "Epoch 32/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9931 - val_loss: 1.0283\n",
            "Epoch 33/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9934 - val_loss: 1.0283\n",
            "Epoch 34/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9928 - val_loss: 1.0283\n",
            "Epoch 35/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9927 - val_loss: 1.0282\n",
            "Epoch 36/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.9926 - val_loss: 1.0282\n",
            "Epoch 37/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9938 - val_loss: 1.0282\n",
            "Epoch 38/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9933 - val_loss: 1.0283\n",
            "Epoch 39/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9925 - val_loss: 1.0282\n",
            "Epoch 40/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9917 - val_loss: 1.0282\n",
            "Epoch 41/200\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.9947 - val_loss: 1.0282\n",
            "Epoch 42/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9914 - val_loss: 1.0282\n",
            "Epoch 43/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9923 - val_loss: 1.0282\n",
            "Epoch 44/200\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.9929 - val_loss: 1.0282\n",
            "Epoch 45/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.9934 - val_loss: 1.0282\n",
            "Epoch 46/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.9928 - val_loss: 1.0282\n",
            "Epoch 47/200\n",
            "44/44 [==============================] - 1s 13ms/step - loss: 0.9947 - val_loss: 1.0282\n",
            "Epoch 48/200\n",
            "44/44 [==============================] - 1s 13ms/step - loss: 0.9938 - val_loss: 1.0282\n",
            "Epoch 49/200\n",
            "44/44 [==============================] - 1s 13ms/step - loss: 0.9927 - val_loss: 1.0282\n",
            "Epoch 50/200\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.9928 - val_loss: 1.0282\n",
            "Epoch 51/200\n",
            "44/44 [==============================] - 1s 16ms/step - loss: 0.9940 - val_loss: 1.0282\n",
            "Epoch 52/200\n",
            "44/44 [==============================] - 1s 12ms/step - loss: 0.9948 - val_loss: 1.0282\n",
            "Epoch 53/200\n",
            "44/44 [==============================] - 1s 13ms/step - loss: 0.9942 - val_loss: 1.0282\n",
            "Epoch 54/200\n",
            "44/44 [==============================] - 1s 14ms/step - loss: 0.9926 - val_loss: 1.0282\n",
            "Epoch 55/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.9940 - val_loss: 1.0282\n",
            "Epoch 56/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.9925 - val_loss: 1.0282\n",
            "Epoch 57/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9935 - val_loss: 1.0282\n",
            "Epoch 58/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9923 - val_loss: 1.0282\n",
            "Epoch 59/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9932 - val_loss: 1.0282\n",
            "Epoch 60/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.9926 - val_loss: 1.0282\n",
            "Epoch 61/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9933 - val_loss: 1.0282\n",
            "Epoch 62/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9928 - val_loss: 1.0282\n",
            "Epoch 63/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.9916 - val_loss: 1.0282\n",
            "Epoch 64/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9931 - val_loss: 1.0282\n",
            "Epoch 65/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9934 - val_loss: 1.0282\n",
            "Epoch 66/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.9933 - val_loss: 1.0282\n",
            "Epoch 67/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.9938 - val_loss: 1.0282\n",
            "Epoch 68/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9927 - val_loss: 1.0282\n",
            "Epoch 69/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9918 - val_loss: 1.0282\n",
            "Epoch 70/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9933 - val_loss: 1.0282\n",
            "Epoch 71/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9920 - val_loss: 1.0282\n",
            "Epoch 72/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.9917 - val_loss: 1.0282\n",
            "Epoch 73/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9930 - val_loss: 1.0282\n",
            "Epoch 74/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9918 - val_loss: 1.0281\n",
            "Epoch 75/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9948 - val_loss: 1.0282\n",
            "Epoch 76/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9923 - val_loss: 1.0282\n",
            "Epoch 77/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9928 - val_loss: 1.0282\n",
            "Epoch 78/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9925 - val_loss: 1.0282\n",
            "Epoch 79/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9921 - val_loss: 1.0282\n",
            "Epoch 80/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9923 - val_loss: 1.0282\n",
            "Epoch 81/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9920 - val_loss: 1.0282\n",
            "Epoch 82/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9929 - val_loss: 1.0282\n",
            "Epoch 83/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9924 - val_loss: 1.0282\n",
            "Epoch 84/200\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 0.9922 - val_loss: 1.0282\n",
            "Epoch 85/200\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.9926 - val_loss: 1.0282\n",
            "Epoch 86/200\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 0.9946 - val_loss: 1.0282\n",
            "Epoch 87/200\n",
            "44/44 [==============================] - 1s 12ms/step - loss: 0.9936 - val_loss: 1.0282\n",
            "Epoch 88/200\n",
            "44/44 [==============================] - 1s 21ms/step - loss: 0.9917 - val_loss: 1.0282\n",
            "Epoch 89/200\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.9935 - val_loss: 1.0282\n",
            "Epoch 90/200\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 0.9927 - val_loss: 1.0282\n",
            "Epoch 91/200\n",
            "44/44 [==============================] - 1s 12ms/step - loss: 0.9934 - val_loss: 1.0282\n",
            "Epoch 92/200\n",
            "44/44 [==============================] - 1s 11ms/step - loss: 0.9932 - val_loss: 1.0282\n",
            "Epoch 93/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9922 - val_loss: 1.0282\n",
            "Epoch 94/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9954 - val_loss: 1.0282\n",
            "Epoch 95/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9937 - val_loss: 1.0282\n",
            "Epoch 96/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9920 - val_loss: 1.0282\n",
            "Epoch 97/200\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.9929 - val_loss: 1.0282\n",
            "Epoch 98/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9920 - val_loss: 1.0282\n",
            "Epoch 99/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9920 - val_loss: 1.0282\n",
            "Epoch 100/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.9932 - val_loss: 1.0282\n",
            "Epoch 101/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9922 - val_loss: 1.0282\n",
            "Epoch 102/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.9927 - val_loss: 1.0282\n",
            "Epoch 103/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9937 - val_loss: 1.0281\n",
            "Epoch 104/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.9937 - val_loss: 1.0282\n",
            "Epoch 105/200\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.9917 - val_loss: 1.0282\n",
            "Epoch 106/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9946 - val_loss: 1.0282\n",
            "Epoch 107/200\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.9918 - val_loss: 1.0282\n",
            "Epoch 108/200\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.9922 - val_loss: 1.0282\n",
            "Epoch 109/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9922 - val_loss: 1.0282\n",
            "Epoch 110/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9935 - val_loss: 1.0282\n",
            "Epoch 111/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.9932 - val_loss: 1.0282\n",
            "Epoch 112/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9921 - val_loss: 1.0282\n",
            "Epoch 113/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9917 - val_loss: 1.0282\n",
            "Epoch 114/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9946 - val_loss: 1.0282\n",
            "Epoch 115/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9937 - val_loss: 1.0282\n",
            "Epoch 116/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9938 - val_loss: 1.0282\n",
            "Epoch 117/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9932 - val_loss: 1.0282\n",
            "Epoch 118/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9940 - val_loss: 1.0282\n",
            "Epoch 119/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9929 - val_loss: 1.0282\n",
            "Epoch 120/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9941 - val_loss: 1.0282\n",
            "Epoch 121/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9922 - val_loss: 1.0282\n",
            "Epoch 122/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9924 - val_loss: 1.0282\n",
            "Epoch 123/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9951 - val_loss: 1.0282\n",
            "Epoch 124/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9936 - val_loss: 1.0282\n",
            "Epoch 125/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9921 - val_loss: 1.0282\n",
            "Epoch 126/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9934 - val_loss: 1.0282\n",
            "Epoch 127/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9929 - val_loss: 1.0282\n",
            "Epoch 128/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9936 - val_loss: 1.0282\n",
            "Epoch 129/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9938 - val_loss: 1.0282\n",
            "Epoch 130/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9950 - val_loss: 1.0282\n",
            "Epoch 131/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9943 - val_loss: 1.0282\n",
            "Epoch 132/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9943 - val_loss: 1.0282\n",
            "Epoch 133/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.9933 - val_loss: 1.0282\n",
            "Epoch 134/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9935 - val_loss: 1.0282\n",
            "Epoch 135/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9925 - val_loss: 1.0282\n",
            "Epoch 136/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.9920 - val_loss: 1.0282\n",
            "Epoch 137/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9936 - val_loss: 1.0282\n",
            "Epoch 138/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9929 - val_loss: 1.0282\n",
            "Epoch 139/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9918 - val_loss: 1.0282\n",
            "Epoch 140/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9938 - val_loss: 1.0282\n",
            "Epoch 141/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9953 - val_loss: 1.0282\n",
            "Epoch 142/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9930 - val_loss: 1.0282\n",
            "Epoch 143/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.9924 - val_loss: 1.0282\n",
            "Epoch 144/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.9935 - val_loss: 1.0282\n",
            "Epoch 145/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 0.9925 - val_loss: 1.0282\n",
            "Epoch 146/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9938 - val_loss: 1.0282\n",
            "Epoch 147/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 0.9929 - val_loss: 1.0282\n",
            "Epoch 148/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.9941 - val_loss: 1.0282\n",
            "Epoch 149/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9922 - val_loss: 1.0282\n",
            "Epoch 150/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9923 - val_loss: 1.0282\n",
            "Epoch 151/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9926 - val_loss: 1.0282\n",
            "Epoch 152/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9939 - val_loss: 1.0282\n",
            "Epoch 153/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9927 - val_loss: 1.0282\n",
            "Epoch 154/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9930 - val_loss: 1.0282\n",
            "Epoch 155/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9921 - val_loss: 1.0282\n",
            "Epoch 156/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9938 - val_loss: 1.0282\n",
            "Epoch 157/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9924 - val_loss: 1.0282\n",
            "Epoch 158/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9940 - val_loss: 1.0282\n",
            "Epoch 159/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9931 - val_loss: 1.0282\n",
            "Epoch 160/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9920 - val_loss: 1.0282\n",
            "Epoch 161/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9928 - val_loss: 1.0282\n",
            "Epoch 162/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9934 - val_loss: 1.0282\n",
            "Epoch 163/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9928 - val_loss: 1.0282\n",
            "Epoch 164/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9921 - val_loss: 1.0282\n",
            "Epoch 165/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9922 - val_loss: 1.0282\n",
            "Epoch 166/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9956 - val_loss: 1.0282\n",
            "Epoch 167/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9923 - val_loss: 1.0282\n",
            "Epoch 168/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9936 - val_loss: 1.0282\n",
            "Epoch 169/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9926 - val_loss: 1.0282\n",
            "Epoch 170/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9926 - val_loss: 1.0282\n",
            "Epoch 171/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9933 - val_loss: 1.0282\n",
            "Epoch 172/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9936 - val_loss: 1.0282\n",
            "Epoch 173/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9933 - val_loss: 1.0282\n",
            "Epoch 174/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9922 - val_loss: 1.0282\n",
            "Epoch 175/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9919 - val_loss: 1.0282\n",
            "Epoch 176/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9952 - val_loss: 1.0282\n",
            "Epoch 177/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9917 - val_loss: 1.0282\n",
            "Epoch 178/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9924 - val_loss: 1.0282\n",
            "Epoch 179/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9915 - val_loss: 1.0282\n",
            "Epoch 180/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9935 - val_loss: 1.0282\n",
            "Epoch 181/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.9929 - val_loss: 1.0282\n",
            "Epoch 182/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9930 - val_loss: 1.0282\n",
            "Epoch 183/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9915 - val_loss: 1.0282\n",
            "Epoch 184/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9938 - val_loss: 1.0282\n",
            "Epoch 185/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.9924 - val_loss: 1.0282\n",
            "Epoch 186/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9939 - val_loss: 1.0282\n",
            "Epoch 187/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9939 - val_loss: 1.0282\n",
            "Epoch 188/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9939 - val_loss: 1.0282\n",
            "Epoch 189/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9930 - val_loss: 1.0282\n",
            "Epoch 190/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9922 - val_loss: 1.0282\n",
            "Epoch 191/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9923 - val_loss: 1.0282\n",
            "Epoch 192/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9952 - val_loss: 1.0282\n",
            "Epoch 193/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9948 - val_loss: 1.0282\n",
            "Epoch 194/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9975 - val_loss: 1.0282\n",
            "Epoch 195/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9926 - val_loss: 1.0282\n",
            "Epoch 196/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9939 - val_loss: 1.0282\n",
            "Epoch 197/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9940 - val_loss: 1.0282\n",
            "Epoch 198/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9919 - val_loss: 1.0282\n",
            "Epoch 199/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9939 - val_loss: 1.0282\n",
            "Epoch 200/200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.9921 - val_loss: 1.0282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting the Encoder part of VAE and freezing them"
      ],
      "metadata": {
        "id": "Bo83f55Z-e87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Model(inputs, z)\n",
        "encoder.trainable = False\n",
        "encoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J0cBvnWSKNV",
        "outputId": "10840765-de1b-43d3-bc63-91b6c80bf615"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 19)]         0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 36)           720         ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 72)           2664        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 36)           2628        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 36)           2628        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " z (Lambda)                     (None, 36)           0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,640\n",
            "Trainable params: 0\n",
            "Non-trainable params: 8,640\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_input = Input(shape=(19,))\n",
        "encoded_input = encoder(classifier_input)\n",
        "x1=Dense(128,activation='relu')(encoded_input)\n",
        "x2=layers.Dropout(0.5)(x1)\n",
        "x2=Dense(64,activation='relu')(x2)\n",
        "x2=layers.Dropout(0.25)(x2)\n",
        "x3=Dense(32,activation='relu')(x2)\n",
        "x4=Dense(16,activation='relu')(x3)\n",
        "x5=Dense(8,activation='relu')(x4)\n",
        "x6=Dense(4,activation='relu')(x5)\n",
        "output_layer = Dense(1, activation='sigmoid')(x6)\n",
        "\n",
        "classifier = Model(classifier_input, output_layer)\n",
        "classifier.summary()\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "classifier.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_val, y_val),callbacks=[es])\n"
      ],
      "metadata": {
        "id": "3ga3NymszHzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc769c6-78ea-457e-8741-d624dd6faf6f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 19)]              0         \n",
            "                                                                 \n",
            " model_1 (Functional)        (None, 36)                8640      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               4736      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,417\n",
            "Trainable params: 15,777\n",
            "Non-trainable params: 8,640\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "175/175 [==============================] - 3s 9ms/step - loss: 0.6905 - accuracy: 0.5530 - val_loss: 0.6893 - val_accuracy: 0.5512\n",
            "Epoch 2/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.6870 - accuracy: 0.5616 - val_loss: 0.6887 - val_accuracy: 0.5512\n",
            "Epoch 3/50\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.6874 - accuracy: 0.5614 - val_loss: 0.6883 - val_accuracy: 0.5512\n",
            "Epoch 4/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.6864 - accuracy: 0.5612 - val_loss: 0.6881 - val_accuracy: 0.5512\n",
            "Epoch 5/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.6859 - accuracy: 0.5614 - val_loss: 0.6882 - val_accuracy: 0.5512\n",
            "Epoch 6/50\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6863 - accuracy: 0.5612 - val_loss: 0.6883 - val_accuracy: 0.5512\n",
            "Epoch 7/50\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6864 - accuracy: 0.5614 - val_loss: 0.6881 - val_accuracy: 0.5512\n",
            "Epoch 8/50\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6855 - accuracy: 0.5614 - val_loss: 0.6875 - val_accuracy: 0.5512\n",
            "Epoch 9/50\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6867 - accuracy: 0.5596 - val_loss: 0.6878 - val_accuracy: 0.5512\n",
            "Epoch 10/50\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6864 - accuracy: 0.5614 - val_loss: 0.6883 - val_accuracy: 0.5512\n",
            "Epoch 11/50\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6862 - accuracy: 0.5614 - val_loss: 0.6880 - val_accuracy: 0.5512\n",
            "Epoch 12/50\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6858 - accuracy: 0.5614 - val_loss: 0.6880 - val_accuracy: 0.5512\n",
            "Epoch 13/50\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6858 - accuracy: 0.5614 - val_loss: 0.6879 - val_accuracy: 0.5512\n",
            "Epoch 14/50\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6858 - accuracy: 0.5614 - val_loss: 0.6879 - val_accuracy: 0.5512\n",
            "Epoch 15/50\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6857 - accuracy: 0.5614 - val_loss: 0.6880 - val_accuracy: 0.5512\n",
            "Epoch 16/50\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6857 - accuracy: 0.5614 - val_loss: 0.6880 - val_accuracy: 0.5512\n",
            "Epoch 17/50\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6857 - accuracy: 0.5614 - val_loss: 0.6882 - val_accuracy: 0.5512\n",
            "Epoch 18/50\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6857 - accuracy: 0.5614 - val_loss: 0.6882 - val_accuracy: 0.5512\n",
            "Epoch 18: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f48dbf2f400>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = classifier.evaluate(x_train, y_train)[1]\n",
        "print(f\"Train accuracy: {round(accuracy * 100, 2)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e95e12a-3bb5-4847-bf75-2ad855538774",
        "id": "z2d2oLsAACS0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175/175 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5614\n",
            "Train accuracy: 56.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc2b9016-b9ed-4d80-e2fb-bdcd9d3d75ca",
        "id": "vq-yMdxmACS1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "196/196 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5589\n",
            "Test accuracy: 55.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "1uflynQkypcR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "gCqDeki_EiCA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data = autoencoder.predict(x_train)\n",
        "print(encoded_data.shape)\n",
        "tsne = TSNE(n_components=2, verbose=1, random_state=123)\n",
        "z = tsne.fit_transform(encoded_data)\n",
        "df = pd.DataFrame()\n",
        "df[\"y\"] = y_train\n",
        "df[\"comp-1\"] = z[:,0]\n",
        "df[\"comp-2\"] = z[:,1]\n",
        "\n",
        "sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),\n",
        "                palette=sns.color_palette(\"hls\", 10),\n",
        "                data=df).set(title=\"MNIST data T-SNE projection\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv1T_YglOj4w",
        "outputId": "792ac469-3b37-4d74-a340-5e650de5a82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175/175 [==============================] - 0s 1ms/step\n",
            "(5584, 19)\n",
            "[t-SNE] Computing 91 nearest neighbors...\n",
            "[t-SNE] Indexed 5584 samples in 0.001s...\n",
            "[t-SNE] Computed neighbors for 5584 samples in 0.327s...\n",
            "[t-SNE] Computed conditional probabilities for sample 1000 / 5584\n",
            "[t-SNE] Computed conditional probabilities for sample 2000 / 5584\n",
            "[t-SNE] Computed conditional probabilities for sample 3000 / 5584\n",
            "[t-SNE] Computed conditional probabilities for sample 4000 / 5584\n",
            "[t-SNE] Computed conditional probabilities for sample 5000 / 5584"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data = encoder.predict(x_train)\n",
        "print(encoded_data.shape)\n",
        "tsne = TSNE(n_components=2, verbose=1, random_state=123)\n",
        "z = tsne.fit_transform(encoded_data)\n",
        "df = pd.DataFrame()\n",
        "df[\"y\"] = y_train\n",
        "df[\"comp-1\"] = z[:,0]\n",
        "df[\"comp-2\"] = z[:,1]\n",
        "\n",
        "sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),\n",
        "                palette=sns.color_palette(\"hls\", 10),\n",
        "                data=df).set(title=\"MNIST data T-SNE projection\")"
      ],
      "metadata": {
        "id": "-ILM7W0ZNx-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Measuring Accuracy"
      ],
      "metadata": {
        "id": "mM6xcNVc-rgv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AJ4_Tz0imzrF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}