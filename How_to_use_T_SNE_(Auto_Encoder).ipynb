{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPKVr3W7JNwd4vabJqPIVs6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/midnightripper/accuracy_improvement/blob/main/How_to_use_T_SNE_(Auto_Encoder).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n4W5sADBnfx",
        "outputId": "091d6338-33e7-4c47-ff3b-8c05028e88e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTuKWTvUCDYg"
      },
      "source": [
        "###Prerequisite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd7zXfrBBvqM",
        "outputId": "1842cdfb-7663-4031-e7c9-dba1f2a492e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow-addons) (23.0)\n",
            "Collecting typeguard<3.0.0,>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O7F71cx6BwQW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef4ec3b-35a5-4160-e1c3-c93682c18422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Input\n",
        "from keras.layers import Reshape\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzQisdLRCdAm"
      },
      "source": [
        "Load the train and test data splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c4yofhKpCPsk"
      },
      "outputs": [],
      "source": [
        "GER_test = (np.array(sio.loadmat('/content/drive/MyDrive/training data/GER_test.mat')['GER_test'])).transpose()\n",
        "GER_train = (np.array(sio.loadmat('/content/drive/MyDrive/training data/GER_train.mat')['GER_train'])).transpose()\n",
        "test_frame = pd.DataFrame(GER_test).sort_values(1)\n",
        "train_frame = pd.DataFrame(GER_train).sort_values(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HDdLVz2ChJF",
        "outputId": "aee96b4e-a242-4221-cea9-8e41cc95028d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (6981, 21) - y_train shape: (6981, 21)\n",
            "x_test shape: (6248, 21) - y_test shape: (6248, 21)\n"
          ]
        }
      ],
      "source": [
        "print(f\"x_train shape: {GER_train.shape} - y_train shape: {GER_train.shape}\")\n",
        "print(f\"x_test shape: {GER_test.shape} - y_test shape: {GER_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QKt4urE1O7ke"
      },
      "outputs": [],
      "source": [
        "def get_data_labels(split):\n",
        "    x = pd.DataFrame(split)\n",
        "    labels = x[0].values.astype(np.uint8)\n",
        "    del x[0],x[1]\n",
        "    data = x.values \n",
        "    return data, labels\n",
        "    \n",
        "x_train, y_train = get_data_labels(train_frame.values.tolist())\n",
        "x_test, y_test = get_data_labels(test_frame.values.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(x_train)\n",
        "scaler = StandardScaler()\n",
        "x_train = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)"
      ],
      "metadata": {
        "id": "LiyxoXMIajC_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame(x_test)\n",
        "scaler = StandardScaler()\n",
        "x_test = pd.DataFrame(scaler.fit_transform(df2), columns=df.columns)"
      ],
      "metadata": {
        "id": "4PVlJpiAb1Xq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Size of the training set: {len(x_train)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNcb5GGX3-RC",
        "outputId": "13202892-640d-4752-9003-4dfd11c5e696"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the training set: 6981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Size of the x training set: {len(x_train)}\")\n",
        "print(f\"Size of the x validation set: {len(x_val)}\")\n",
        "print(f\"Size of the y training set: {len(y_train)}\")\n",
        "print(f\"Size of the y validation set: {len(y_val)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8QrrTLl3Vck",
        "outputId": "dce1a16c-5505-4ac9-e779-dba3f0dd40aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the x training set: 5584\n",
            "Size of the x validation set: 1397\n",
            "Size of the y training set: 5584\n",
            "Size of the y validation set: 1397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early stopping to prevent over-fitting"
      ],
      "metadata": {
        "id": "NDyM8dez-mGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
      ],
      "metadata": {
        "id": "g8hamCaPnco_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lt9XHJ8hR2Md"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}